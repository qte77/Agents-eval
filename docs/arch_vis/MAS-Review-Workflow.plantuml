@startuml MAS-Review-Workflow
title PeerRead Evaluation Workflow (with Security Boundaries)

!log Current 'STYLE' dvar: STYLE
!log About to include: styles/github-STYLE.puml
!include styles/github-STYLE.puml

actor User
participant "Manager Agent" as Manager
participant "Researcher Agent" as Researcher
database "PeerRead Dataset" as DB
participant "LLM Provider\n(chat + judge)" as LLM
entity "Evaluation System" as EvalSystem
entity "ReviewPersistence" as Persistence

User -> Manager: Request to evaluate paper "X"
activate Manager

note right of Manager
  MAESTRO L1 (Foundation Model):
  URL validation via validate_url().
  Only allowlisted domains accepted.
end note

Manager -> DB: Get paper content for "X"\n[URL validated â€” SSRF prevention]
activate DB
DB --> Manager: Return full paper content
deactivate DB

note right of Manager
  MAESTRO L3 (Agent Cognitive):
  Prompt sanitization before LLM call.
  Length limits + XML delimiter wrapping.
end note

Manager -> LLM: Generate review using large context\n[Input sanitized]
activate LLM
LLM --> Manager: Return comprehensive review + traces
deactivate LLM

note right of Manager
  MAESTRO L5 (Secure Vault):
  API keys never logged.
  Sensitive data filtered pre-export.
end note

Manager -> Persistence: Save review + execution traces\n[Log scrubbing applied]
activate Persistence
Persistence -> Persistence: Create timestamped JSON file with metadata
Persistence --> Manager: Confirm save
deactivate Persistence

group Optional Delegation
    Manager -> Researcher: Delegate research query
    activate Researcher
    Researcher -> Researcher: Use DuckDuckGo, Tavily, Exa, ...
    Researcher --> Manager: Return research results
    deactivate Researcher
end group

Manager -> EvalSystem: Initiate three-tier evaluation
activate EvalSystem

EvalSystem -> EvalSystem: Traditional Metrics (Text similarity, execution time, ...)
EvalSystem -> EvalSystem: LLM-as-a-Judge (quality + execution assessment)
EvalSystem -> EvalSystem: Graph Analysis (tool calls + complexity)
EvalSystem -> EvalSystem: Composite Score = (Results / Time / Complexity)

EvalSystem --> Manager: Complete evaluation results
deactivate EvalSystem

Manager --> User: Final agent performance score
deactivate Manager
@enduml

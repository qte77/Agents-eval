@startuml metrics-eval-sweep
title Metrics Eval Sweep

!log Current 'STYLE' dvar: STYLE
!log About to include: styles/github-STYLE.puml
!include styles/github-STYLE.puml

participant "Sweep Engine\n(SweepRunner)" as SE
participant "Agentic System\n(app.main)" as AS
participant "Evaluation Engine\n(EvaluationPipeline)" as EE
participant "Result Store\n(results.json)" as RS

SE -> SE: Validate prerequisites\n(claude CLI if --engine=cc)
SE -> RS: Initialize empty results.json

group Composition Sweep [compositions × papers × repetitions]

    loop for each AgentComposition
        loop for each paper_id
            loop for each repetition

                SE -> AS: run(composition, paper_id, engine)

                group Rate-Limit Retry [max 3 attempts, exponential backoff]
                    AS -> EE: Execute evaluation
                    alt Success
                        EE --> AS: CompositeResult\n(tier1/2/3 scores, composite)
                        AS --> SE: CompositeResult
                        SE -> RS: Append result\n(incremental save)
                    else HTTP 429 / Rate Limit
                        AS -> AS: Wait (retry_delay * 2^attempt)
                        AS -> EE: Retry
                    else Max retries exceeded
                        AS --> SE: None (skip, log error)
                    end
                end

            end
        end
    end

end

SE -> SE: Run SweepAnalyzer\n(mean, stddev per composition)
SE -> RS: Write final results.json
SE -> RS: Write summary.md\n(Markdown table per composition)

@enduml

"""
PeerRead evaluation data models.

This module defines Pydantic models specifically for evaluation results
when comparing agent-generated reviews against PeerRead ground truth.
"""

from pydantic import BaseModel, Field

from app.data_models.peerread_models import PeerReadReview


class PeerReadEvalResult(BaseModel):
    """Result of evaluating agent review against PeerRead ground truth."""

    paper_id: str = Field(description="Paper being evaluated")
    agent_review: str = Field(description="Review generated by agent")
    ground_truth_reviews: list[PeerReadReview] = Field(
        description="Original peer reviews from dataset"
    )
    similarity_scores: dict[str, float] = Field(
        description="Similarity metrics (semantic, cosine, jaccard)"
    )
    overall_similarity: float = Field(
        description="Weighted overall similarity score (0-1)"
    )
    recommendation_match: bool = Field(
        description="Whether agent recommendation matches ground truth"
    )
